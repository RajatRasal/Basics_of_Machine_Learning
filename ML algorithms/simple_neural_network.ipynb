{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Neural Networks using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has an input layer and an output layer, and one or more Hidden Layers. Every layer except the input and output layers has a bias neuron and each layer is fully connected to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an neural network has two or more hidden layers it is called a Deep Neural Network (DNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 200\n",
    "n_hidden3 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.05\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X will be the input layer. Each image will be placed along the 1st dimension and each pixel will go down the 2nd dimension. \n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "    image_1 / pixel_1 & image_2 / pixel_1 & \\dots & image_n / pixel_1 \\\\\n",
    "    image_1 / pixel_2 & image_2 / pixel_2 & \\dots & image_n / pixel_2  \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    image_1 / pixel_{784} & image_2 / pixel_{784} & \\dots & image_n / pixel_{784} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "X will be replaced by one training batch at a time, but we dont know the size of each training batch. Hence, the shape of the input layer is $(None, 28 * 28)$. \n",
    "\n",
    "All instances of a training batch are processed at the same time by the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input layer\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The W matrix will hold weights which will be updated during training. It will hold the connection weights between each input and each neuron, hence the shape (n_inputs, n_neurons). It will be initialised with a truncated normal distribution, with a standard deviation: $$\\sigma = \\frac{2}{\\sqrt{n_{inputs}}}$$\n",
    "\n",
    "A truncated normal distribution prevents any larger number which may slow down training.\n",
    "\n",
    "We need to initialise weights randomly so that when each neuron in each layer is updated they will be updated differently.\n",
    "\n",
    "The W (weights) and b (biases) are a part of the trainable variables within the Tensorflow graph. These will be updated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        if activation == \"relu\":\n",
    "            return tf.nn.relu(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", \"relu\")\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", \"relu\")\n",
    "    logits = neuron_layer(hidden2, n_outputs, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully_connected internally creates a weights matrix for the connection weights between each input and each neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dropout regularisation](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf) is applied to every layer of the netural network except the output layer. Since each neuron may or may not be present, there are $2^N$ possible neural networks (N is the total number of dropable neurons) that can be produced to learn a training step. So we essentially have an ensemble neural network of all the neural networks produced at each training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, dropout\n",
    "\n",
    "keep_prob = 0.5\n",
    "activation_fn = tf.nn.elu\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "\n",
    "with tf.name_scope(\"fc_dnn\"):\n",
    "    X_drop = dropout(X, keep_prob=keep_prob, is_training=is_training)\n",
    "    \n",
    "    hidden1 = fully_connected(X_drop, n_hidden1,\n",
    "                              activation_fn=activation_fn, \n",
    "                              scope=\"hidden1\")\n",
    "    hidden1_drop = dropout(hidden1, keep_prob=keep_prob, is_training=is_training)\n",
    "    \n",
    "    hidden2 = fully_connected(hidden1, n_hidden2,\n",
    "                              activation_fn=activation_fn,\n",
    "                              scope=\"hidden2\")\n",
    "    hidden2_drop = dropout(hidden2, keep_prob=keep_prob, is_training=is_training)\n",
    "    \n",
    "    hidden3 = fully_connected(hidden2, n_hidden2,\n",
    "                              activation_fn=activation_fn,\n",
    "                              scope=\"hidden3\")\n",
    "    hidden3_drop = dropout(hidden3, keep_prob=keep_prob, is_training=is_training)\n",
    "    \n",
    "    logits = fully_connected(hidden3_drop, n_outputs, scope=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                           momentum=momentum,\n",
    "                                           use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-7187608d1af6>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/rajatrasal/anaconda3/envs/ACRE_project/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/rajatrasal/anaconda3/envs/ACRE_project/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/rajatrasal/anaconda3/envs/ACRE_project/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/rajatrasal/anaconda3/envs/ACRE_project/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.92 Test accuracy: 0.9096\n",
      "1 Train accuracy: 1.0 Test accuracy: 0.9671\n",
      "2 Train accuracy: 0.96 Test accuracy: 0.974\n",
      "3 Train accuracy: 0.94 Test accuracy: 0.9893\n",
      "4 Train accuracy: 1.0 Test accuracy: 0.9799\n",
      "5 Train accuracy: 1.0 Test accuracy: 0.9829\n",
      "6 Train accuracy: 1.0 Test accuracy: 0.9991\n",
      "7 Train accuracy: 1.0 Test accuracy: 0.9992\n",
      "8 Train accuracy: 1.0 Test accuracy: 0.9991\n",
      "9 Train accuracy: 1.0 Test accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for _ in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch,\n",
    "                                             is_training: True})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch,\n",
    "                                             is_training: False})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, \n",
    "                                            y: mnist.test.labels,\n",
    "                                            is_training: False})\n",
    "        print(epoch,\n",
    "              \"Train accuracy:\", acc_train,\n",
    "              \"Test accuracy:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ACRE_project]",
   "language": "python",
   "name": "conda-env-ACRE_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
